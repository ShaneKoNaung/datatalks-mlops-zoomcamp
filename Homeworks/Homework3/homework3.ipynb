{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5a28f25",
   "metadata": {},
   "source": [
    "# Q1. Human-readable name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225424a9",
   "metadata": {},
   "source": [
    "We can specify the task name by using\n",
    "\n",
    "@task(retries=3, retry_delay_seconds=2, name=\"Read taxi data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39359a1f",
   "metadata": {},
   "source": [
    "# Q2. Cron\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e691a92",
   "metadata": {},
   "source": [
    "The screenshot is using the crontab.guru[https://crontab.guru/#0_9_3_*_*]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e71ac0",
   "metadata": {},
   "source": [
    "![cron](imgs/cron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edae7d45",
   "metadata": {},
   "source": [
    "The correct answer is 0 9 3 * *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa672367",
   "metadata": {},
   "source": [
    "# Q3. RMSE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0260764d",
   "metadata": {},
   "source": [
    "The data path is added before performing custom run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1d22ce",
   "metadata": {},
   "source": [
    "![data custom](imgs/para.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381391be",
   "metadata": {},
   "source": [
    "The results in UI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f621cb92",
   "metadata": {},
   "source": [
    "![result](imgs/val_rmse.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fd37d5",
   "metadata": {},
   "source": [
    "The rmse value is 5.19931"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0371ba2",
   "metadata": {},
   "source": [
    "# Q4. RMSE (Markdown Artifact)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d29bff3",
   "metadata": {},
   "source": [
    "![markdown](imgs/markdown.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dc2570",
   "metadata": {},
   "source": [
    "The answer is 5.37"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1776ac",
   "metadata": {},
   "source": [
    "# Q5. Emails\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24ec259",
   "metadata": {},
   "source": [
    "Email block is created using create_email_block.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0493df8f",
   "metadata": {},
   "source": [
    "![email_block](imgs/email_block.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b84a73",
   "metadata": {},
   "source": [
    "The name of the pre-built prefect-email task function is email_send_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c867b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a22470d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
